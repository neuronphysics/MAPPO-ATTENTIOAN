_target_: src.policies.ippo.IPPO
params:
  n_layers: 2
  hidden_dim: 128
  learning_rate: 0.0005
  gamma: 0.99
  gae_lambda: 0.95
  gae: True
  n_agents: ${n_agents}
  ent_coef: 0.01
  vf_coef: 0.5
  norm_adv: True
  clip_coef: 0.2
  clip_vloss: True
  max_grad_norm: 10
  target_kl: null
  update_epochs: 10
  num_minibatches: 1
  rollout_threads: ${rollout_threads}
  env_steps: ${env_steps}
  activation: tanh
  continuous_action: ${continuous_action}
  shared_actor: False
  shared_critic: False
  type: mlp
  conv_out_size: 64
  